  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:05,  1.73it/s] 20%|██        | 2/10 [00:01<00:04,  1.65it/s] 30%|███       | 3/10 [00:06<00:17,  2.53s/it] 40%|████      | 4/10 [00:06<00:10,  1.75s/it] 50%|█████     | 5/10 [00:07<00:07,  1.41s/it] 60%|██████    | 6/10 [00:07<00:03,  1.04it/s] 70%|███████   | 7/10 [00:07<00:02,  1.28it/s] 80%|████████  | 8/10 [00:08<00:01,  1.42it/s] 90%|█████████ | 9/10 [00:08<00:00,  1.59it/s]100%|██████████| 10/10 [00:09<00:00,  1.81it/s]100%|██████████| 10/10 [00:09<00:00,  1.08it/s]
/home/mschlichting/RLSoups/average_models.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  weights = torch.nn.functional.softmax(performance)
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  1.25it/s]100%|██████████| 1/1 [00:00<00:00,  1.25it/s]
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:02<00:23,  2.60s/it] 20%|██        | 2/10 [00:05<00:22,  2.79s/it] 30%|███       | 3/10 [00:08<00:21,  3.08s/it] 40%|████      | 4/10 [00:10<00:13,  2.30s/it] 50%|█████     | 5/10 [00:11<00:09,  1.83s/it] 60%|██████    | 6/10 [00:12<00:06,  1.60s/it] 70%|███████   | 7/10 [00:14<00:05,  1.77s/it] 80%|████████  | 8/10 [00:14<00:02,  1.40s/it] 90%|█████████ | 9/10 [00:17<00:01,  1.82s/it]100%|██████████| 10/10 [00:19<00:00,  1.77s/it]100%|██████████| 10/10 [00:19<00:00,  1.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:02<00:00,  2.58s/it]100%|██████████| 1/1 [00:02<00:00,  2.58s/it]
0 0
Current Training Reward 288.52906216
0 1
Current Training Reward 292.63107516
0 2
Current Training Reward 103.61726011
0 3
Current Training Reward 268.96176055
0 4
Current Training Reward 347.93729037
0 5
Current Training Reward 39.13346591
0 6
Current Training Reward 175.22538861
0 7
Current Training Reward 270.60945026999997
0 8
Current Training Reward 193.92958200000004
0 9
Current Training Reward 42.163019999999996
[276.55525156189054, 368.98440402883114, 982.1393061888621, 286.58064130477334, 483.3796737574186, 38.77914703322419, 173.30305957923548, 268.9661906472673, 187.1047156937364, 140.01306521259593]
[288.52906216, 292.63107516, 103.61726011, 268.96176055, 347.93729037, 39.13346591, 175.22538861, 270.60945026999997, 193.92958200000004, 42.163019999999996]
tensor([1.5825e-26, 9.5679e-25, 0.0000e+00, 5.0277e-35, 1.0000e+00, 0.0000e+00,
        0.0000e+00, 2.6118e-34, 0.0000e+00, 0.0000e+00])
all weights top-performance [485.012633421383]
mean [276.55525156189054, 368.98440402883114, 982.1393061888621, 286.58064130477334, 483.3796737574186, 38.77914703322419, 173.30305957923548, 268.9661906472673, 187.1047156937364, 140.01306521259593]
1 0
Current Training Reward 825.12972482
1 1
Current Training Reward 788.5355870100002
1 2
Current Training Reward 661.1052827999999
1 3
Current Training Reward 770.48220529
1 4
Current Training Reward 587.65801219
1 5
Current Training Reward 670.87432881
1 6
Current Training Reward 832.6046784000001
1 7
Current Training Reward 307.86675478999996
1 8
Current Training Reward 838.3483126100001
1 9
Current Training Reward 743.7767348400001
[1707.7077047062976, 1861.8150470692642, 2112.4398073049247, 711.045865908012, 703.1727871069543, 716.1685677054438, 1535.1308672123882, 337.93191715116086, 1950.3381444801848, 1120.8606881607795]
[825.12972482, 788.5355870100002, 661.1052827999999, 770.48220529, 587.65801219, 670.87432881, 832.6046784000001, 307.86675478999996, 838.3483126100001, 743.7767348400001]
tensor([1.8106e-06, 2.3185e-22, 0.0000e+00, 3.3475e-30, 0.0000e+00, 0.0000e+00,
        3.1928e-03, 0.0000e+00, 9.9681e-01, 8.4470e-42])
all weights top-performance [1811.2283388713554]
mean [1707.7077047062976, 1861.8150470692642, 2112.4398073049247, 711.045865908012, 703.1727871069543, 716.1685677054438, 1535.1308672123882, 337.93191715116086, 1950.3381444801848, 1120.8606881607795]
