  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:00<00:01,  8.34it/s] 20%|██        | 2/10 [00:01<00:06,  1.32it/s] 30%|███       | 3/10 [00:02<00:05,  1.17it/s] 40%|████      | 4/10 [00:03<00:05,  1.00it/s] 50%|█████     | 5/10 [00:08<00:11,  2.33s/it] 60%|██████    | 6/10 [00:09<00:07,  1.88s/it] 70%|███████   | 7/10 [00:10<00:04,  1.53s/it] 80%|████████  | 8/10 [00:10<00:02,  1.19s/it] 90%|█████████ | 9/10 [00:11<00:01,  1.12s/it]100%|██████████| 10/10 [00:12<00:00,  1.05s/it]100%|██████████| 10/10 [00:12<00:00,  1.23s/it]
/home/mschlichting/RLSoups/average_models.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  weights = torch.nn.functional.softmax(performance)
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:01<00:00,  1.22s/it]100%|██████████| 1/1 [00:01<00:00,  1.22s/it]
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:01<00:09,  1.02s/it] 20%|██        | 2/10 [00:02<00:11,  1.49s/it] 30%|███       | 3/10 [00:03<00:08,  1.18s/it] 40%|████      | 4/10 [00:06<00:10,  1.78s/it] 50%|█████     | 5/10 [00:07<00:08,  1.64s/it] 60%|██████    | 6/10 [00:11<00:09,  2.31s/it] 70%|███████   | 7/10 [00:12<00:05,  1.86s/it] 80%|████████  | 8/10 [00:13<00:03,  1.60s/it] 90%|█████████ | 9/10 [00:14<00:01,  1.45s/it]100%|██████████| 10/10 [00:16<00:00,  1.63s/it]100%|██████████| 10/10 [00:16<00:00,  1.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:01<00:00,  1.20s/it]100%|██████████| 1/1 [00:01<00:00,  1.20s/it]
0 0
Current Training Reward -17.18172936
0 1
Current Training Reward 459.73183993999993
0 2
Current Training Reward 380.31993217
0 3
Current Training Reward 511.22585541
0 4
Current Training Reward 65.88103231999999
0 5
Current Training Reward 370.47694952000006
0 6
Current Training Reward 287.36443279
0 7
Current Training Reward 195.45303696999997
0 8
Current Training Reward 87.30711958000002
0 9
Current Training Reward 180.00123752000002
[-17.667315746972502, 594.970588630599, 405.0111287911909, 648.966190440036, 930.300623076619, 409.8519745826517, 257.57494297116426, 184.99831698137933, 88.65025600339807, 278.4035546739213]
[-17.18172936, 459.73183993999993, 380.31993217, 511.22585541, 65.88103231999999, 370.47694952000006, 287.36443279, 195.45303696999997, 87.30711958000002, 180.00123752000002]
tensor([0.0000e+00, 4.3294e-23, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00])
all weights top-performance [646.9982446866485]
mean [-17.667315746972502, 594.970588630599, 405.0111287911909, 648.966190440036, 930.300623076619, 409.8519745826517, 257.57494297116426, 184.99831698137933, 88.65025600339807, 278.4035546739213]
1 0
Current Training Reward 831.98360273
1 1
Current Training Reward 533.6399497699999
1 2
Current Training Reward 814.4398380599999
1 3
Current Training Reward 736.56290319
1 4
Current Training Reward 714.0145428799999
1 5
Current Training Reward 706.1377813600002
1 6
Current Training Reward 438.93463089
1 7
Current Training Reward 487.28307301
1 8
Current Training Reward 571.67893467
1 9
Current Training Reward 749.5547246000001
[478.8476827683138, 801.330890058397, 370.25972692428024, 1426.8599676506487, 885.5454500167918, 1780.6682915279864, 471.81330567150815, 465.09390587736095, 644.6959824221731, 1117.614022615705]
[831.98360273, 533.6399497699999, 814.4398380599999, 736.56290319, 714.0145428799999, 706.1377813600002, 438.93463089, 487.28307301, 571.67893467, 749.5547246000001]
tensor([1.0000e+00, 0.0000e+00, 2.4035e-08, 3.6252e-42, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5908e-36])
all weights top-performance [674.2249662177521]
mean [478.8476827683138, 801.330890058397, 370.25972692428024, 1426.8599676506487, 885.5454500167918, 1780.6682915279864, 471.81330567150815, 465.09390587736095, 644.6959824221731, 1117.614022615705]
